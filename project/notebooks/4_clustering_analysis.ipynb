{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a226319",
   "metadata": {},
   "source": [
    "# 4. Clustering the Entire Dataset\n",
    "Using DBSCAN to identify natural clusters of board games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de711db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Set display options and styling\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Create output directory for plots if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('../plots'):\n",
    "    os.makedirs('../plots')\n",
    "if not os.path.exists('../frames'):\n",
    "    os.makedirs('../frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "filtered_df = pd.read_csv('../frames/filtered_games.csv')\n",
    "all_binary_cols = np.load('../frames/all_binary_cols.npy', allow_pickle=True)\n",
    "\n",
    "print(f\"Loaded {len(filtered_df)} games with {len(all_binary_cols)} binary features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8485e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PCA results\n",
    "pca_df = pd.read_csv('../frames/pca_results.csv')\n",
    "import joblib\n",
    "pca = joblib.load('../frames/pca_model.pkl')\n",
    "n_components = pca.n_components_\n",
    "\n",
    "# Get the PCA result from the dataframe\n",
    "pca_result = pca_df[[f'PC{i+1}' for i in range(n_components)]].values\n",
    "\n",
    "print(f\"Loaded PCA results with {n_components} components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32751c5-6768-4ef6-b378-fb7cafe23eae",
   "metadata": {},
   "source": [
    "# Use k-distance graph to find appropriate eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aff591-8be0-43a6-b5ca-de85060692ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find appropriate epsilon with k-distance graph\n",
    "print(\"Generating k-distance graph...\")\n",
    "neighbors = NearestNeighbors(n_neighbors=20)\n",
    "neighbors_fit = neighbors.fit(pca_result)\n",
    "distances, indices = neighbors_fit.kneighbors(pca_result)\n",
    "\n",
    "# Sort distances\n",
    "distances = np.sort(distances[:, 19])\n",
    "\n",
    "# Plot k-distance graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances)\n",
    "plt.axhline(y=0.8, color='r', linestyle='--', label='Potential epsilon')\n",
    "plt.title('K-Distance Graph')\n",
    "plt.xlabel('Data Points (sorted by distance)')\n",
    "plt.ylabel('Distance to 20th Nearest Neighbor')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('../plots/k_distance_graph.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a708cc6-d10c-4718-85d0-59d15e806ad6",
   "metadata": {},
   "source": [
    "# Grid Search to eps and min_samples Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641d37e-ebf2-41bd-8074-d04f267b145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a range of epsilon and min_samples values\n",
    "print(\"\\nTrying different DBSCAN parameters:\")\n",
    "for eps in [0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]:\n",
    "    for min_samples in [10, 15, 20, 25]:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(pca_result)\n",
    "        \n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = list(labels).count(-1)\n",
    "        \n",
    "        print(f\"eps={eps}, min_samples={min_samples}: {n_clusters} clusters, {n_noise} noise points ({n_noise/len(labels)*100:.1f}%)\")\n",
    "        \n",
    "        # Calculate silhouette score if more than one cluster\n",
    "        if n_clusters > 1:\n",
    "            # We need to filter both the data points and labels to exclude noise points\n",
    "            mask = labels != -1\n",
    "            silhouette_avg = silhouette_score(pca_result[mask], labels[mask])\n",
    "            print(f\"Silhouette score (excluding noise): {silhouette_avg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b94886-f4b9-4484-b1d6-c7ad9454be0c",
   "metadata": {},
   "source": [
    "# Run DBSCAN With Chosen Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55da27-ae1e-4a69-9232-bc619b66f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.8\n",
    "min_samples = 15\n",
    "print(f\"\\nApplying DBSCAN with eps={eps}, min_samples={min_samples}\")\n",
    "\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "cluster_labels = dbscan.fit_predict(pca_result)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "pca_df['DBSCAN_Cluster'] = cluster_labels\n",
    "filtered_df['DBSCAN_Cluster'] = cluster_labels\n",
    "\n",
    "# Analyze clusters\n",
    "n_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "n_noise = list(cluster_labels).count(-1)\n",
    "print(f\"DBSCAN found {n_clusters} clusters and {n_noise} noise points ({n_noise/len(cluster_labels)*100:.1f}%)\")\n",
    "\n",
    "# Calculate silhouette score if more than one cluster\n",
    "if n_clusters > 1:\n",
    "    # We need to filter both the data points and labels to exclude noise points\n",
    "    mask = cluster_labels != -1\n",
    "    silhouette_avg = silhouette_score(pca_result[mask], cluster_labels[mask])\n",
    "    print(f\"Silhouette score (excluding noise): {silhouette_avg:.4f}\")\n",
    "\n",
    "# Visualize clusters in 2D PCA space\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(pca_df['PC1'], pca_df['PC2'], \n",
    "                     c=pca_df['DBSCAN_Cluster'], cmap='viridis', \n",
    "                     alpha=0.6, s=30)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.title('Board Game Clusters in PCA Space (PC1 vs PC2)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.savefig('../plots/dbscan_clusters.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c2982-3954-4f23-b837-07daf5fa27d8",
   "metadata": {},
   "source": [
    "# Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c451bff-15eb-4f68-a055-5f37a5cdd08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating distribution by cluster\n",
    "if n_clusters > 0:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(x='DBSCAN_Cluster', y='AvgRating', data=filtered_df)\n",
    "    plt.title('Rating Distribution by Cluster')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.show()\n",
    "    plt.savefig('../plots/rating_by_cluster.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5e18f-8873-476c-8f4e-f1c52e84851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze clusters\n",
    "if n_clusters > 0:\n",
    "    print(\"\\nCluster Statistics:\")\n",
    "    cluster_stats = filtered_df.groupby('DBSCAN_Cluster').agg({\n",
    "        'AvgRating': ['mean', 'std', 'count'],\n",
    "        'NumUserRatings': ['mean', 'median']\n",
    "    })\n",
    "    print(cluster_stats)\n",
    "\n",
    "    # For each cluster, find defining features\n",
    "    print(\"\\nDefining features for each cluster:\")\n",
    "    for i in sorted(set(cluster_labels)):\n",
    "        if i == -1:\n",
    "            continue  # Skip noise points\n",
    "            \n",
    "        cluster_games = filtered_df[filtered_df['DBSCAN_Cluster'] == i]\n",
    "        other_games = filtered_df[filtered_df['DBSCAN_Cluster'] != i]\n",
    "        \n",
    "        # Compare feature presence\n",
    "        distinctive_features = []\n",
    "        for col in all_binary_cols:\n",
    "            cluster_mean = cluster_games[col].mean()\n",
    "            other_mean = other_games[col].mean()\n",
    "            diff = cluster_mean - other_mean\n",
    "            distinctive_features.append((col, diff, cluster_mean, other_mean))\n",
    "        \n",
    "        # Sort by absolute difference\n",
    "        distinctive_features.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        print(f\"\\nCluster {i} ({len(cluster_games)} games, avg rating: {cluster_games['AvgRating'].mean():.2f}):\")\n",
    "        print(\"Distinctive features:\")\n",
    "        for feat, diff, c_mean, o_mean in distinctive_features[:10]:\n",
    "            print(f\"  {feat}: {diff:.4f} ({c_mean*100:.1f}% vs {o_mean*100:.1f}%)\")\n",
    "        \n",
    "        # Show example games\n",
    "        top_games = cluster_games.sort_values('AvgRating', ascending=False).head(3)\n",
    "        print(\"Example games:\")\n",
    "        for _, game in top_games.iterrows():\n",
    "            print(f\"  {game['Name']} ({game['YearPublished']}) - Rating: {game['AvgRating']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1ac3a-62a8-48a0-bbdc-baf6e9941877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
