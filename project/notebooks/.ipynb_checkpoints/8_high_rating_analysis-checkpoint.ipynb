{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ee60a3",
   "metadata": {},
   "source": [
    "# 8. Market Segment Analysis for High Ratings\n",
    "Deep dive into clusters of highly-rated board games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Set display options and styling\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Create output directory for plots if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('../plots'):\n",
    "    os.makedirs('../plots')\n",
    "if not os.path.exists('../frames'):\n",
    "    os.makedirs('../frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eacf0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "filtered_df = pd.read_csv('../frames/filtered_games.csv')\n",
    "all_binary_cols = np.load('../frames/all_binary_cols.npy', allow_pickle=True)\n",
    "\n",
    "print(f\"Loaded {len(filtered_df)} games with {len(all_binary_cols)} binary features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91892a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Random Forest results\n",
    "feature_importance = pd.read_csv('../frames/feature_importance.csv')\n",
    "\n",
    "print(\"Loaded Random Forest feature importance results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6390d5-4c85-4843-a3dd-06ee5639ef72",
   "metadata": {},
   "source": [
    "# Find optimal eps through k-distance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797f243-695a-480c-bfb1-76f1432b8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select high-rated games (7.5+)\n",
    "#high_rated = filtered_df[filtered_df['Rating_Bracket'] == '8+'].copy()\n",
    "high_rated = filtered_df[filtered_df['AvgRating'] >= 7.5].copy()\n",
    "print(f\"Found {len(high_rated)} highly-rated games (7.5+)\")\n",
    "\n",
    "# Apply PCA with variance-based component selection\n",
    "pca_high = PCA()\n",
    "pca_high.fit(high_rated[all_binary_cols])\n",
    "explained_variance = np.cumsum(pca_high.explained_variance_ratio_)\n",
    "n_components_high = np.argmax(explained_variance >= 0.8) + 1\n",
    "print(f\"Using {n_components_high} components (80% variance) for high-rated games\")\n",
    "\n",
    "pca_high = PCA(n_components=n_components_high)\n",
    "#pca_high = PCA(n_components=20)\n",
    "pca_result_high = pca_high.fit_transform(high_rated[all_binary_cols])\n",
    "\n",
    "# Find appropriate epsilon\n",
    "neighbors = NearestNeighbors(n_neighbors=10)\n",
    "neighbors_fit = neighbors.fit(pca_result_high)\n",
    "distances, _ = neighbors_fit.kneighbors(pca_result_high)\n",
    "sorted_distances = np.sort(distances[:, 9])\n",
    "\n",
    "# Choose epsilon with the same approach as before\n",
    "elbow_index = max(1, len(sorted_distances) // 10)  # Simple heuristic\n",
    "eps_high = max(0.1, sorted_distances[elbow_index])  # Ensure epsilon is at least 0.1\n",
    "print(f\"Using epsilon = {eps_high:.2f}\")\n",
    "\n",
    "# Plot k-distance graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sorted_distances)\n",
    "plt.axhline(y=0.7, color='r', linestyle='--', label='Potential epsilon')\n",
    "plt.title('K-Distance Graph for High-Rated Games')\n",
    "plt.xlabel('Points sorted by distance')\n",
    "plt.ylabel('Distance to 10th nearest neighbor')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('../plots/k_distance_high_rated.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4277b9-fc65-4574-bdab-08aed8b27c5a",
   "metadata": {},
   "source": [
    "# Run DBSCAN With Chosen Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8263836-90bd-43cb-b7c7-7f5be9b22e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN with chosen epsilon\n",
    "eps_high = eps_high  # Adjust based on the k-distance plot\n",
    "min_samples_high = 15\n",
    "print(f\"Applying DBSCAN with eps={eps_high}, min_samples={min_samples_high}\")\n",
    "\n",
    "dbscan_high = DBSCAN(eps=eps_high, min_samples=min_samples_high)\n",
    "high_clusters = dbscan_high.fit_predict(pca_result_high)\n",
    "\n",
    "# Add clusters to dataframe\n",
    "high_rated['Cluster'] = high_clusters\n",
    "\n",
    "# Analyze clusters\n",
    "n_clusters = len(set(high_clusters)) - (1 if -1 in high_clusters else 0)\n",
    "n_noise = list(high_clusters).count(-1)\n",
    "print(f\"DBSCAN found {n_clusters} clusters and {n_noise} noise points ({n_noise/len(high_clusters)*100:.1f}%)\")\n",
    "\n",
    "# Calculate silhouette score if more than one cluster\n",
    "if n_clusters > 1:\n",
    "    # We need to filter both the data points and labels to exclude noise points\n",
    "    mask = high_clusters != -1\n",
    "    silhouette_avg = silhouette_score(pca_result_high[mask], high_clusters[mask])\n",
    "    print(f\"Silhouette score (excluding noise): {silhouette_avg:.4f}\")\n",
    "\n",
    "if n_clusters > 0:\n",
    "    # Visualize clusters in 2D PCA space (PC1 vs PC2)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(\n",
    "        pca_result_high[:, 0], \n",
    "        pca_result_high[:, 1], \n",
    "        c=high_clusters, \n",
    "        cmap='viridis', \n",
    "        alpha=0.6, \n",
    "        s=30\n",
    "    )\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.title('High-Rated Board Game Clusters in PCA Space')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.savefig('../plots/high_rated_clusters.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf195138-5db2-47e6-8db6-909b5bfad68c",
   "metadata": {},
   "source": [
    "# Defining Features For Each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c477d-ec59-468e-a2c1-191c68d1eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_clusters > 0:\n",
    "    # For each cluster, find defining features\n",
    "    print(\"\\nDefining features for each high-rated cluster:\")\n",
    "    for i in sorted(set(high_clusters)):\n",
    "        if i == -1:\n",
    "            continue  # Skip noise points\n",
    "            \n",
    "        cluster_games = high_rated[high_rated['Cluster'] == i]\n",
    "        other_games = high_rated[high_rated['Cluster'] != i]\n",
    "        \n",
    "        # Compare feature presence\n",
    "        distinctive_features = []\n",
    "        for col in all_binary_cols:\n",
    "            cluster_mean = cluster_games[col].mean()\n",
    "            other_mean = other_games[col].mean()\n",
    "            diff = cluster_mean - other_mean\n",
    "            distinctive_features.append((col, diff, cluster_mean, other_mean))\n",
    "        \n",
    "        # Sort by absolute difference\n",
    "        distinctive_features.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        print(f\"\\nCluster {i} ({len(cluster_games)} games, avg rating: {cluster_games['AvgRating'].mean():.2f}):\")\n",
    "        print(\"Distinctive features:\")\n",
    "        for feat, diff, c_mean, o_mean in distinctive_features[:10]:\n",
    "            print(f\"  {feat}: {diff:.4f} ({c_mean*100:.1f}% vs {o_mean*100:.1f}%)\")\n",
    "        \n",
    "        # Show example games\n",
    "        top_games = cluster_games.sort_values('AvgRating', ascending=False).head(3)\n",
    "        print(\"Example games:\")\n",
    "        for _, game in top_games.iterrows():\n",
    "            print(f\"  {game['Name']} ({game['YearPublished']}) - Rating: {game['AvgRating']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c980d-b98c-4103-9a72-adda13576d60",
   "metadata": {},
   "source": [
    "# Analyze Success Factors in Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2d69c-a4d2-43c8-96be-650e4b58623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out noise points (-1)\n",
    "cluster_column = 'Cluster'\n",
    "clustered_games = high_rated[high_rated[cluster_column] >= 0]\n",
    "\n",
    "for cluster_id in sorted(clustered_games[cluster_column].unique()):\n",
    "    cluster_games = clustered_games[clustered_games[cluster_column] == cluster_id]\n",
    "    \n",
    "    print(f\"Cluster {cluster_id} ({len(cluster_games)} games):\")\n",
    "    \n",
    "    # Average complexity and playtime if available\n",
    "    if 'AvgComplexity' in high_rated.columns:\n",
    "        print(f\"  Average Complexity: {cluster_games['AvgComplexity'].mean():.2f}\")\n",
    "    \n",
    "    if 'PlayingTime' in high_rated.columns:\n",
    "        print(f\"  Average Playing Time: {cluster_games['PlayingTime'].mean():.2f} minutes\")\n",
    "    \n",
    "    # Player counts\n",
    "    if 'MinPlayers' in high_rated.columns and 'MaxPlayers' in high_rated.columns:\n",
    "        print(f\"  Player Count: {cluster_games['MinPlayers'].mean():.1f}-{cluster_games['MaxPlayers'].mean():.1f} players\")\n",
    "    \n",
    "    # Ratings statistics\n",
    "    print(f\"  Average Rating: {cluster_games['AvgRating'].mean():.2f}\")\n",
    "    print(f\"  Rating Range: {cluster_games['AvgRating'].min():.2f}-{cluster_games['AvgRating'].max():.2f}\")\n",
    "    \n",
    "    # Number of User Ratings (popularity metric)\n",
    "    if 'NumUserRatings' in high_rated.columns:\n",
    "        print(f\"  Average User Ratings: {cluster_games['NumUserRatings'].mean():.1f}\")\n",
    "    \n",
    "    # Top game examples\n",
    "    top_games = cluster_games.sort_values('AvgRating', ascending=False).head(3)\n",
    "    print(\"  Top rated games:\")\n",
    "    for _, game in top_games.iterrows():\n",
    "        print(f\"    {game['Name']} ({game['YearPublished']}) - {game['AvgRating']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f1ed6-e4a9-42cd-97d3-7150254617fb",
   "metadata": {},
   "source": [
    "# Analyze Trends Within Each Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be300d-2dc3-4aad-ab29-b288086def55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out noise points (-1)\n",
    "clustered_games = high_rated[high_rated[cluster_column] >= 0]\n",
    "\n",
    "# Create year bins for analysis\n",
    "clustered_games['YearBin'] = pd.cut(\n",
    "    clustered_games['YearPublished'],\n",
    "    bins=[1900, 1990, 2000, 2010, 2015, 2020, 2025],\n",
    "    labels=['Pre-1990', '1990s', '2000s', '2010-2015', '2015-2020', '2020+']\n",
    ")\n",
    "\n",
    "for cluster_id in sorted(clustered_games[cluster_column].unique()):\n",
    "    cluster_games = clustered_games[clustered_games[cluster_column] == cluster_id]\n",
    "    \n",
    "    print(f\"Cluster {cluster_id} ({len(cluster_games)} games):\")\n",
    "    \n",
    "    # Calculate correlation between year and rating\n",
    "    year_rating_corr = cluster_games['YearPublished'].corr(cluster_games['AvgRating'])\n",
    "    print(f\"  Year-Rating Correlation: {year_rating_corr:.3f}\")\n",
    "    \n",
    "    # Average rating by year range\n",
    "    year_ratings = cluster_games.groupby('YearBin')['AvgRating'].agg(['mean', 'count'])\n",
    "    print(\"  Ratings by year range:\")\n",
    "    for year_bin, row in year_ratings.iterrows():\n",
    "        if row['count'] > 0:  # Only show non-empty years\n",
    "            print(f\"    {year_bin}: {row['mean']:.2f} ({int(row['count'])} games)\")\n",
    "    \n",
    "    # Plot trend if there are enough games\n",
    "    if len(cluster_games) >= 10:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.regplot(x='YearPublished', y='AvgRating', data=cluster_games, \n",
    "                   scatter_kws={'alpha': 0.5}, line_kws={'color': 'red'})\n",
    "        plt.title(f'Rating Trend Over Time for Cluster {cluster_id}')\n",
    "        plt.xlabel('Year Published')\n",
    "        plt.ylabel('Average Rating')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        plt.savefig(f'../plots/cluster_{cluster_id}_trend.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866725a-46b2-4b47-b4e3-b18a805464df",
   "metadata": {},
   "source": [
    "# Comparison with Regression Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0553d5d-d63a-4793-86d5-453b24dd29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key features from our regression analysis\n",
    "top_positive_features = feature_importance.head(6)['Feature'].tolist()\n",
    "top_negative_features = ['Roll / Spin and Move', 'Card Game']\n",
    "\n",
    "# Filter out noise points (-1)\n",
    "clustered_games = high_rated[high_rated[cluster_column] >= 0]\n",
    "\n",
    "# Overall presence in highly rated games (for comparison)\n",
    "overall_presence = {}\n",
    "for feature in top_positive_features + top_negative_features:\n",
    "    if feature in high_rated.columns:\n",
    "        overall_presence[feature] = high_rated[feature].mean()\n",
    "\n",
    "for cluster_id in sorted(clustered_games[cluster_column].unique()):\n",
    "    cluster_games = clustered_games[clustered_games[cluster_column] == cluster_id]\n",
    "    \n",
    "    print(f\"Cluster {cluster_id} ({len(cluster_games)} games):\")\n",
    "    \n",
    "    # Check presence of positive regression features\n",
    "    print(\"  Positive predictors of high ratings:\")\n",
    "    for feature in top_positive_features:\n",
    "        if feature in high_rated.columns:\n",
    "            presence = cluster_games[feature].mean() * 100\n",
    "            overall = overall_presence[feature] * 100\n",
    "            diff = presence - overall\n",
    "            print(f\"    {feature}: {presence:.1f}% (overall: {overall:.1f}%, diff: {diff:+.1f}%)\")\n",
    "    \n",
    "    # Check presence of negative regression features\n",
    "    print(\"  Negative predictors of high ratings:\")\n",
    "    for feature in top_negative_features:\n",
    "        if feature in high_rated.columns:\n",
    "            presence = cluster_games[feature].mean() * 100\n",
    "            overall = overall_presence[feature] * 100\n",
    "            diff = presence - overall\n",
    "            print(f\"    {feature}: {presence:.1f}% (overall: {overall:.1f}%, diff: {diff:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12156af9-420e-4557-8e4c-6e4607a8431f",
   "metadata": {},
   "source": [
    "# Find Potential Outliers in Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad534a-6b75-4d52-bd00-d69fc12383a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out noise points (-1)\n",
    "clustered_games = high_rated[high_rated[cluster_column] >= 0]\n",
    "\n",
    "for cluster_id in sorted(clustered_games[cluster_column].unique()):\n",
    "    cluster_games = clustered_games[clustered_games[cluster_column] == cluster_id]\n",
    "    \n",
    "    print(f\"Cluster {cluster_id} ({len(cluster_games)} games):\")\n",
    "    \n",
    "    # Find distinctive features for this cluster\n",
    "    distinctive_features = []\n",
    "    for col in all_binary_cols:\n",
    "        cluster_mean = cluster_games[col].mean()\n",
    "        other_mean = high_rated[high_rated[cluster_column] != cluster_id][col].mean()\n",
    "        diff = cluster_mean - other_mean\n",
    "        \n",
    "        # Consider a feature distinctive if the difference is substantial\n",
    "        if abs(diff) > 0.3:\n",
    "            distinctive_features.append((col, diff))\n",
    "    \n",
    "    # Sort by absolute difference\n",
    "    distinctive_features.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    # Get key positive and negative distinctive features\n",
    "    pos_features = [f for f, d in distinctive_features if d > 0 and cluster_games[f].mean() > 0.8]\n",
    "    neg_features = [f for f, d in distinctive_features if d < 0]\n",
    "    \n",
    "    # Find games that don't fit the cluster pattern\n",
    "    outliers = []\n",
    "    for _, game in cluster_games.iterrows():\n",
    "        reasons = []\n",
    "        \n",
    "        # Check if missing key positive features\n",
    "        for feature in pos_features[:3]:  # Check top 3 positive features\n",
    "            if game[feature] == 0:\n",
    "                reasons.append(f\"Missing {feature}\")\n",
    "        \n",
    "        # Check if has features the cluster typically doesn't have\n",
    "        for feature in neg_features[:3]:  # Check top 3 negative features\n",
    "            if game[feature] == 1:\n",
    "                reasons.append(f\"Has unexpected {feature}\")\n",
    "        \n",
    "        if reasons:\n",
    "            outliers.append((game['Name'], game['YearPublished'], game['AvgRating'], reasons))\n",
    "    \n",
    "    # Sort by rating (highest first) and show top outliers\n",
    "    outliers.sort(key=lambda x: x[2], reverse=True)\n",
    "    if outliers:\n",
    "        print(\"  Potential innovation outliers:\")\n",
    "        for name, year, rating, reasons in outliers[:3]:\n",
    "            print(f\"    {name} ({year}) - Rating: {rating:.2f}\")\n",
    "            print(f\"      Reasons: {', '.join(reasons)}\")\n",
    "    else:\n",
    "        print(\"  No significant outliers found in this cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275738d5-d363-4478-abb1-9cad030df95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
