{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5818a30",
   "metadata": {},
   "source": [
    "# 7. Rating-Stratified Clustering\n",
    "Analyzing clusters within different rating brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Set display options and styling\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Create output directory for plots if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('../plots'):\n",
    "    os.makedirs('../plots')\n",
    "if not os.path.exists('../frames'):\n",
    "    os.makedirs('../frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "filtered_df = pd.read_csv('../frames/filtered_games.csv')\n",
    "all_binary_cols = np.load('../frames/all_binary_cols.npy', allow_pickle=True)\n",
    "\n",
    "print(f\"Loaded {len(filtered_df)} games with {len(all_binary_cols)} binary features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd261647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Random Forest results\n",
    "feature_importance = pd.read_csv('../frames/feature_importance.csv')\n",
    "\n",
    "print(\"Loaded Random Forest feature importance results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a99c9-7ab8-41f9-910d-f382c4ceae06",
   "metadata": {},
   "source": [
    "# Cluster Each Rating Bin and Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509814e-a745-46cf-882d-9cd4607e5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store data for visualizations\n",
    "rating_bin_clusters = []  # For cluster count visualization\n",
    "feature_dist = []  # For feature distribution visualization\n",
    "top_features_by_bin = {}  # For top features visualization\n",
    "\n",
    "# Use the Rating_Bracket we created earlier\n",
    "for rating_bin in filtered_df['Rating_Bracket'].unique():\n",
    "    bin_games = filtered_df[filtered_df['Rating_Bracket'] == rating_bin].copy()\n",
    "    \n",
    "    if len(bin_games) < 100:  # Skip bins with too few games\n",
    "        print(f\"Skipping {rating_bin} rated games: only {len(bin_games)} games\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nAnalyzing {rating_bin} rated games ({len(bin_games)} games)\")\n",
    "    \n",
    "    # Apply PCA with variance-based component selection\n",
    "    pca_bin = PCA()\n",
    "    pca_bin.fit(bin_games[all_binary_cols])\n",
    "    explained_variance = np.cumsum(pca_bin.explained_variance_ratio_)\n",
    "    n_components_bin = np.argmax(explained_variance >= 0.8) + 1\n",
    "    print(f\"Using {n_components_bin} components (80% variance) for {rating_bin} rating bin\")\n",
    "    \n",
    "    pca_bin = PCA(n_components=n_components_bin)\n",
    "    pca_result_bin = pca_bin.fit_transform(bin_games[all_binary_cols])\n",
    "    \n",
    "    # Find appropriate epsilon using k-distance\n",
    "    neighbors = NearestNeighbors(n_neighbors=10)\n",
    "    neighbors_fit = neighbors.fit(pca_result_bin)\n",
    "    distances, _ = neighbors_fit.kneighbors(pca_result_bin)\n",
    "    sorted_distances = np.sort(distances[:, 9])\n",
    "    \n",
    "    # Choose epsilon with a more principled approach - find the elbow point\n",
    "    elbow_index = max(1, len(sorted_distances) // 10)  # Simple heuristic\n",
    "    eps_bin = max(0.1, sorted_distances[elbow_index])  # Ensure epsilon is at least 0.1\n",
    "    print(f\"Using epsilon = {eps_bin:.2f}\")\n",
    "    \n",
    "    # Apply DBSCAN\n",
    "    min_samples_bin = 10\n",
    "    dbscan_bin = DBSCAN(eps=eps_bin, min_samples=min_samples_bin)\n",
    "    clusters_bin = dbscan_bin.fit_predict(pca_result_bin)\n",
    "    \n",
    "    # Add clusters to dataframe\n",
    "    bin_games['Rating_Bin_Cluster'] = clusters_bin\n",
    "    \n",
    "    # Analyze clusters\n",
    "    n_clusters = len(set(clusters_bin)) - (1 if -1 in clusters_bin else 0)\n",
    "    n_noise = list(clusters_bin).count(-1)\n",
    "    noise_pct = (n_noise / len(clusters_bin)) * 100\n",
    "    print(f\"Found {n_clusters} clusters and {n_noise} noise points ({noise_pct:.1f}%)\")\n",
    "    \n",
    "    # Store data for cluster count visualization\n",
    "    rating_bin_clusters.append({\n",
    "        'Rating Bin': rating_bin,\n",
    "        'Number of Clusters': n_clusters,\n",
    "        'Games': len(bin_games),\n",
    "        'Noise Percentage': noise_pct\n",
    "    })\n",
    "    \n",
    "    # Get top features for this rating bin\n",
    "    feature_presence = bin_games[all_binary_cols].mean()\n",
    "    top_features = feature_presence.nlargest(10)\n",
    "    top_features_by_bin[rating_bin] = top_features\n",
    "    \n",
    "    # Calculate feature prevalence for top features from feature_importance\n",
    "    important_features = feature_importance.head(15)['Feature'].tolist()\n",
    "    \n",
    "    for feature in important_features:\n",
    "        if feature in bin_games.columns:\n",
    "            prevalence = bin_games[feature].mean() * 100  # Convert to percentage\n",
    "            feature_dist.append({\n",
    "                'Rating Bin': rating_bin,\n",
    "                'Feature': feature,\n",
    "                'Prevalence': prevalence\n",
    "            })\n",
    "    \n",
    "    if n_clusters > 0:\n",
    "        # Use Decision Tree to understand cluster characteristics\n",
    "        if n_clusters >= 2:  # Need at least 2 clusters for classification\n",
    "            # Prepare data for decision tree (excluding noise points)\n",
    "            X_tree = bin_games[bin_games['Rating_Bin_Cluster'] != -1][all_binary_cols]\n",
    "            y_tree = bin_games[bin_games['Rating_Bin_Cluster'] != -1]['Rating_Bin_Cluster']\n",
    "            \n",
    "            # Train a decision tree\n",
    "            tree = DecisionTreeClassifier(max_depth=4)  # Limit depth for interpretability\n",
    "            tree.fit(X_tree, y_tree)\n",
    "            \n",
    "            # Feature importance\n",
    "            tree_importance = pd.DataFrame({\n",
    "                'Feature': all_binary_cols,\n",
    "                'Importance': tree.feature_importances_\n",
    "            }).sort_values('Importance', ascending=False)\n",
    "            \n",
    "            print(\"\\nTop features for distinguishing clusters:\")\n",
    "            print(tree_importance.head(10))\n",
    "            \n",
    "            # Visualize the tree\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plot_tree(tree, feature_names=all_binary_cols, \n",
    "                     class_names=[str(i) for i in tree.classes_], \n",
    "                     filled=True, rounded=True, fontsize=8)\n",
    "            plt.title(f'Decision Tree for {rating_bin} Rating Bin Clusters')\n",
    "            plt.show()\n",
    "            plt.savefig(f'../plots/decision_tree_{rating_bin}.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "        # Show cluster statistics\n",
    "        cluster_stats = bin_games.groupby('Rating_Bin_Cluster').agg({\n",
    "            'AvgRating': ['mean', 'count'],\n",
    "        })\n",
    "        print(\"Cluster statistics:\")\n",
    "        print(cluster_stats)\n",
    "        \n",
    "        # For each cluster, show example games\n",
    "        for i in sorted(set(clusters_bin)):\n",
    "            if i == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_bin_games = bin_games[bin_games['Rating_Bin_Cluster'] == i]\n",
    "            \n",
    "            print(f\"\\nCluster {i} ({len(cluster_bin_games)} games, avg rating: {cluster_bin_games['AvgRating'].mean():.2f}):\")\n",
    "            \n",
    "            # Show example games\n",
    "            top_games = cluster_bin_games.sort_values('AvgRating', ascending=False).head(3)\n",
    "            print(\"Top games:\")\n",
    "            for _, game in top_games.iterrows():\n",
    "                print(f\"  {game['Name']} ({game['YearPublished']}) - Rating: {game['AvgRating']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64efe27a-c46f-4097-87ee-f7c8148d659e",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93c4fd-fa30-49ad-9c3e-a58bd5221672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Top Features by Rating Bin visualization\n",
    "if top_features_by_bin:\n",
    "    # Get all unique top features across rating bins\n",
    "    all_top_features = set()\n",
    "    for features in top_features_by_bin.values():\n",
    "        all_top_features.update(features.index)\n",
    "    \n",
    "    # Create a dataframe for the heatmap - features by rating bins\n",
    "    heatmap_data = np.zeros((len(all_top_features), len(top_features_by_bin)))\n",
    "    heatmap_df = pd.DataFrame(\n",
    "        heatmap_data,\n",
    "        index=sorted(all_top_features),\n",
    "        columns=sorted(top_features_by_bin.keys())\n",
    "    )\n",
    "    \n",
    "    # Fill in the dataframe with feature prevalence values\n",
    "    for rating_bin, features in top_features_by_bin.items():\n",
    "        for feature, value in features.items():\n",
    "            heatmap_df.loc[feature, rating_bin] = value\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(12, len(all_top_features) * 0.4))\n",
    "    sns.heatmap(heatmap_df, annot=True, fmt='.2f', cmap='viridis')\n",
    "    plt.title('Top Features by Rating Bin')\n",
    "    plt.xlabel('Rating Bin')\n",
    "    plt.ylabel('Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('../plots/rating_bin_top_features.png')\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"Insufficient data to create feature importance plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9a27c-ff39-4d5f-94f2-055128024272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cluster Count by Rating Bin visualization\n",
    "if rating_bin_clusters:\n",
    "    # Sort by rating bin\n",
    "    sorted_bins = ['<5', '5-6', '6-7', '7-8', '8+']\n",
    "    cluster_count_df = pd.DataFrame(rating_bin_clusters)\n",
    "    \n",
    "    # Reorder rows according to sorted_bins if possible\n",
    "    if all(bin_name in sorted_bins for bin_name in cluster_count_df['Rating Bin']):\n",
    "        cluster_count_df['Sort_Order'] = cluster_count_df['Rating Bin'].apply(lambda x: sorted_bins.index(x))\n",
    "        cluster_count_df = cluster_count_df.sort_values('Sort_Order').drop('Sort_Order', axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    ax1 = plt.gca()\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot cluster counts\n",
    "    bars = ax1.bar(cluster_count_df['Rating Bin'], cluster_count_df['Number of Clusters'], color='teal', alpha=0.7)\n",
    "    ax1.set_ylabel('Number of Distinct Clusters', color='teal')\n",
    "    ax1.tick_params(axis='y', labelcolor='teal')\n",
    "    \n",
    "    # Plot game count as line\n",
    "    ax2.plot(cluster_count_df['Rating Bin'], cluster_count_df['Games'], 'ro-', linewidth=2)\n",
    "    ax2.set_ylabel('Number of Games', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    plt.title('Number of Distinct Clusters by Rating Bin')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels for cluster counts\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(\n",
    "            bar.get_x() + bar.get_width()/2.,\n",
    "            height + 0.1,\n",
    "            f'{int(height)}',\n",
    "            ha='center',\n",
    "            color='teal'\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('../plots/rating_bin_cluster_counts.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Also create noise percentage visualization\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    bars = plt.bar(cluster_count_df['Rating Bin'], cluster_count_df['Noise Percentage'], color='lightgray')\n",
    "    plt.title('Noise Percentage in Rating Bin Clustering')\n",
    "    plt.xlabel('Rating Bin')\n",
    "    plt.ylabel('Percentage of Games Classified as Noise')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width()/2.,\n",
    "            height + 1,\n",
    "            f'{height:.1f}%',\n",
    "            ha='center'\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('../plots/rating_bin_noise_percentage.png')\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"Insufficient data to create cluster count plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17553c-c82d-4f8f-bcad-ba3a19bb4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Distribution Across Rating Bins visualization\n",
    "if feature_dist:\n",
    "    feature_dist_df = pd.DataFrame(feature_dist)\n",
    "    \n",
    "    # Create a heatmap of feature prevalence by rating bin\n",
    "    pivot_df = feature_dist_df.pivot(index='Feature', columns='Rating Bin', values='Prevalence')\n",
    "    \n",
    "    # Sort columns if possible\n",
    "    if all(bin_name in sorted_bins for bin_name in pivot_df.columns):\n",
    "        pivot_df = pivot_df[sorted(pivot_df.columns, key=lambda x: sorted_bins.index(x))]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(pivot_df, annot=True, fmt='.1f', cmap='viridis')\n",
    "    plt.title('Important Feature Prevalence (%) by Rating Bin')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('../plots/rating_bin_feature_distribution.png')\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"Insufficient data to create feature distribution plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ab493-bdee-4a31-b5b6-4cf18d2b000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Additional visualization: components needed by rating bin\n",
    "if rating_bin_clusters:\n",
    "    # Extract PCA components information by rating bin\n",
    "    components_by_rating = []\n",
    "    for rating_bin in filtered_df['Rating_Bracket'].unique():\n",
    "        bin_games = filtered_df[filtered_df['Rating_Bracket'] == rating_bin].copy()\n",
    "        \n",
    "        if len(bin_games) < 100:  # Skip bins with too few games\n",
    "            continue\n",
    "        \n",
    "        # Calculate components for 80% variance\n",
    "        pca_temp = PCA()\n",
    "        pca_temp.fit(bin_games[all_binary_cols])\n",
    "        explained_var = np.cumsum(pca_temp.explained_variance_ratio_)\n",
    "        n_comp = np.argmax(explained_var >= 0.8) + 1\n",
    "        \n",
    "        components_by_rating.append({\n",
    "            'Rating Bin': rating_bin,\n",
    "            'Components': n_comp,\n",
    "            'Games': len(bin_games)\n",
    "        })\n",
    "    \n",
    "    # Create dataframe\n",
    "    comp_df = pd.DataFrame(components_by_rating)\n",
    "    \n",
    "    # Sort by rating bin if possible\n",
    "    if all(bin_name in sorted_bins for bin_name in comp_df['Rating Bin']):\n",
    "        comp_df['Sort_Order'] = comp_df['Rating Bin'].apply(lambda x: sorted_bins.index(x))\n",
    "        comp_df = comp_df.sort_values('Sort_Order').drop('Sort_Order', axis=1)\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    ax1 = plt.gca()\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot components\n",
    "    bars = ax1.bar(comp_df['Rating Bin'], comp_df['Components'], color='steelblue', alpha=0.7)\n",
    "    ax1.set_ylabel('PCA Components for 80% Variance', color='steelblue')\n",
    "    ax1.tick_params(axis='y', labelcolor='steelblue')\n",
    "    \n",
    "    # Plot game count as line\n",
    "    ax2.plot(comp_df['Rating Bin'], comp_df['Games'], 'ro-', linewidth=2)\n",
    "    ax2.set_ylabel('Number of Games', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    plt.title('PCA Dimensionality by Rating Bin')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels for components\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(\n",
    "            bar.get_x() + bar.get_width()/2.,\n",
    "            height + 1,\n",
    "            f'{int(height)}',\n",
    "            ha='center',\n",
    "            color='steelblue'\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('../plots/rating_bin_component_complexity.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b330ab-766d-4ec5-8ffb-42f1923fbc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
