{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f2debd",
   "metadata": {},
   "source": [
    "# 2. PCA Analysis\n",
    "Reducing dimensionality of binary board game features and visualize PCA space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set display options and styling\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Create output directory for plots if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists('../plots'):\n",
    "    os.makedirs('../plots')\n",
    "if not os.path.exists('../frames'):\n",
    "    os.makedirs('../frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6011caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "filtered_df = pd.read_csv('../frames/filtered_games.csv')\n",
    "all_binary_cols = np.load('../frames/all_binary_cols.npy', allow_pickle=True)\n",
    "\n",
    "print(f\"Loaded {len(filtered_df)} games with {len(all_binary_cols)} binary features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb63fb-f582-4a45-bfe5-1e5b72629779",
   "metadata": {},
   "source": [
    "# Finding Optimal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42ec8f-46ed-4116-bb61-8102be4c96ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensionality\n",
    "print(\"Applying PCA...\")\n",
    "# Select only the binary features for PCA\n",
    "feature_df = filtered_df[all_binary_cols].copy()\n",
    "\n",
    "# Check for any remaining NaN values\n",
    "nan_count = feature_df.isna().sum().sum()\n",
    "if nan_count > 0:\n",
    "    print(f\"Found {nan_count} NaN values. Filling with 0...\")\n",
    "    feature_df = feature_df.fillna(0)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(feature_df)\n",
    "\n",
    "# Plot explained variance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by PCA Components')\n",
    "plt.axhline(y=0.7, color='r', linestyle='-', label='70% Explained Variance')\n",
    "plt.axhline(y=0.8, color='g', linestyle='-', label='80% Explained Variance')\n",
    "plt.axhline(y=0.9, color='b', linestyle='-', label='90% Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('../plots/pca_explained_variance.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Determine optimal number of components\n",
    "n_components_80 = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.8) + 1\n",
    "n_components_90 = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.9) + 1\n",
    "print(f\"Number of components for 80% variance: {n_components_80}\")\n",
    "print(f\"Number of components for 90% variance: {n_components_90}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3325d-338a-49ad-9237-ef5fe20c3d78",
   "metadata": {},
   "source": [
    "# Analyze Final PCA Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab83d8b-6d5c-4b3e-b7e9-9ade2ee83043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a balance between variance explained and number of components\n",
    "n_components = n_components_80\n",
    "print(f\"\\nUsing {n_components} components for further analysis\")\n",
    "\n",
    "# Apply PCA with selected number of components\n",
    "pca = PCA(n_components=n_components)\n",
    "pca_result = pca.fit_transform(feature_df)\n",
    "\n",
    "# Create a dataframe with PCA results\n",
    "pca_df = pd.DataFrame(\n",
    "    data=pca_result,\n",
    "    columns=[f'PC{i+1}' for i in range(n_components)]\n",
    ")\n",
    "\n",
    "# Add relevant information from the original dataset\n",
    "pca_df['BGGId'] = filtered_df['BGGId'].values\n",
    "pca_df['Name'] = filtered_df['Name'].values\n",
    "pca_df['AvgRating'] = filtered_df['AvgRating'].values\n",
    "pca_df['Year'] = filtered_df['YearPublished'].values\n",
    "pca_df['NumUserRatings'] = filtered_df['NumUserRatings'].values\n",
    "pca_df['Rating_Bracket'] = filtered_df['Rating_Bracket'].values\n",
    "\n",
    "# Check PCA explained variance in more detail\n",
    "print(\"\\nIndividual explained variance per component:\")\n",
    "for i, var in enumerate(pca.explained_variance_ratio_[:20]):\n",
    "    print(f\"PC{i+1}: {var:.4f} ({var*100:.2f}%)\")\n",
    "\n",
    "# Examine feature importance in first few principal components\n",
    "print(\"\\nTop features in first few principal components:\")\n",
    "for i in range(min(5, n_components)):\n",
    "    component = pd.Series(\n",
    "        pca.components_[i],\n",
    "        index=all_binary_cols\n",
    "    )\n",
    "    # Get top positive and negative contributors\n",
    "    top_pos = component.nlargest(5)\n",
    "    top_neg = component.nsmallest(5)\n",
    "    \n",
    "    print(f\"\\nPC{i+1} Top Positive Contributors:\")\n",
    "    for feat, val in top_pos.items():\n",
    "        print(f\"  {feat}: {val:.4f}\")\n",
    "    \n",
    "    print(f\"PC{i+1} Top Negative Contributors:\")\n",
    "    for feat, val in top_neg.items():\n",
    "        print(f\"  {feat}: {val:.4f}\")\n",
    "\n",
    "# Find potential outliers\n",
    "from scipy import stats\n",
    "# Z-score for each PCA component\n",
    "z_scores = pd.DataFrame()\n",
    "for col in pca_df.columns[:n_components]:\n",
    "    z_scores[col] = np.abs(stats.zscore(pca_df[col]))\n",
    "# Games with extreme values\n",
    "outliers = pca_df[(z_scores > 3).any(axis=1)]\n",
    "print(f\"\\nNumber of potential outliers: {len(outliers)}\")\n",
    "print(\"Example outliers:\")\n",
    "print(outliers[['Name', 'AvgRating', 'NumUserRatings']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37466fc-088b-4364-b799-9e4cc3086987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data distribution in PCA space\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'], alpha=0.3, s=10)\n",
    "plt.title('Distribution of Games in PCA Space (PC1 vs PC2)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid(True)\n",
    "plt.savefig('../plots/pca_distribution.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c866ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA results for other notebooks\n",
    "pca_df.to_csv('../frames/pca_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff550f8-d056-45f0-93a1-f2a590e41de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
